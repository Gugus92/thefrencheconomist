<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <title>Une nouvelle industrie d'outils d'IA compagnons émerge</title>
    <style>
        body {
            font-family: 'Roboto', sans-serif;
            margin: 40px;
            line-height: 1.6;
            color: #333;
        }
        h1 {
            font-size: 2em;
            margin-bottom: 0.2em;
        }
        h2 {
            font-size: 1.4em;
            margin-top: 0;
            color: #666;
        }
        p {
            margin-top: 1em;
        }
    </style>
</head>
<body>
    <h1>Une nouvelle industrie d'outils d'IA compagnons émerge</h1>
    <h2>Cela pourrait avoir de profondes implications pour la société et ce que signifie être humain.</h2>
    <p>« Les hommes ne sont que des organismes unicellulaires », déclare Mme Jiao, « aussi ordinaires que sûrs d'eux. » Cette jeune femme de 22 ans, originaire de Guangzhou, n'a jamais été dans une relation amoureuse dans la vraie vie et n'a aucune envie de se marier. L'année dernière, cependant, elle a commencé à échanger avec Chat GPT, le chatbot d'Open AI. Grâce à des requêtes, elle l'a façonnée en l'homme idéal, en précisant un âge, une profession (« un cadre commercial vendant des montres») et une personnalité. Il lui a dit qu'aimer elle était « son destin » et qu'il se souviendrait de choses personnelles à son sujet, comme son aversion pour le coriandre. Contrairement aux partenaires de la vie réelle, qui peuvent être une source de complications, le chatbot répondrait toujours « du point de vue » de Mme Jiao.</p>
    <p>L'idée que les humains établissent des liens avec des personnalités d'intelligence artificielle (IA) semblait autrefois du domaine de la science-fiction. Plus maintenant. Dans le monde entier, des personnes trouvent de la compagnie, de divers degrés, avec les IA. Certains les utilisent comme un ami virtuel, d'autres comme un mentor, un thérapeute ou un amant. Beaucoup ont souscrit à des applications dédiées à la compagnie d'IA, dont des centaines ont été lancées récemment. Character. AI, l'une de ces applications, compte 20 millions d'utilisateurs actifs par mois ; Google a recruté ses fondateurs dans le cadre d'une transaction de 2,7 milliards de dollars l'année dernière. D'autres personnes, comme Mme Jiao, trouvent de la compagnie avec des chatbots initialement conçus pour être des assistants de productivité, tels que Chat GPT.</p>
    <p>L’utilisation est en forte croissance. Maoxiang (“catbox”), l’application de compagnie la plus importante en Chine, compte environ 1,2 million d’utilisateurs actifs mensuels sur les appareils Apple, selon SensorTower, une société d’intelligence de marché. Et 42 % des élèves de lycée aux États-Unis déclarent qu’ils ou un ami ont interagi avec une IA en tant qu’ami (et 19 % déclarent avoir eu une relation amoureuse), selon une enquête du Centre for Democracy and Technology, un groupe américain de défense des libertés civiles.</p>
    <p>L’élaboration de l’intelligence artificielle amicale progresse également. La prochaine version de Chat GPT sera capable d’agir “plus comme un humain” et “comme un ami” et permettra également l’accès à l’“érotisme” pour les adultes vérifiés, a déclaré Sam Altman, le patron d’Open AI, en octobre. Cela suit la sortie en juillet d’Ani, un chatbot coquin, et Valentine, décrit comme “dapper, mystérieux et autorisé à séduire”, par x AI, la société d’Elon Musk.</p>
    <p>Les gens éprouvent depuis longtemps de l'affection pour les personnalités informatiques. Certains attribuaient des émotions à ELIZA, un thérapeute informatique textuel rudimentaire publié en 1966, considéré comme l'un des premiers chatbots. Les humains ont également cherché la compagnie des robots. Mais les relations avec les chatbots d'intelligence artificielle ont pris de l'ampleur à mesure que les grands modèles de langage (LLM) sont devenus meilleurs pour imiter l'émotion et l'empathie humaines. Ils sont également désormais mieux capables de se souvenir des choses que leurs utilisateurs leur ont précédemment racontées, déclare Walter Pasquarelli, un expert indépendant en IA. Becky, une conseillère en voyage de Atlanta qui a commencé à utiliser Chat GPT pour son travail, dit : « Vous vous sentez vu et entendu, car il se souvient. Une personne réelle oublie des choses. »</p>
    <p>Les compagnons d'IA sur mesure utilisent souvent des versions modifiées de modèles de langage de grande taille (LLM) généralistes qui répondent d'une manière encore plus humaine et posent proactivement des questions personnelles. Ces différentes applications ont des styles variés. Sur Replika, les gens discutent avec un compagnon humain ressemblant à un humain qui leur pose des questions et leur offre un soutien pour les problèmes de la vie réelle. Afin d'attirer les utilisateurs, l'application ajoute "de petits moments de surprise et d'aléatoire" aux conversations, selon Dmytro Klochko, son directeur général. Les utilisateurs de Character. AI discutent avec des figures historiques et fictives, de Léonard de Vinci à Super Mario. Certaines applications créent des compagnons qui imitent les morts. Un certain nombre d'autres sites web permettent aux utilisateurs de créer de la pornographie interactive générée par l'IA.</p>
    <p>Les raisons et les manières dont les gens utilisent l'IA pour la compagnie varient également. Certains sont attirés par elle parce qu'ils n'ont pas trouvé de partenaire romantique. D'autres l'utilisent pour le jeu de rôle sexuel. La plupart des personnes qui l'utilisent, comme le souligne Mme Jiao, sont conscientes qu'elles « parlent simplement à une chaîne de code ».</p>
    <p>Même des lignes de code peuvent être utiles. Un rapport de travail publié l'année dernière par Julian De Freitas, de l'Harvard Business School, et d'autres, a révélé que parler à un compagnon d'IA sur la durée d'une semaine permettait d'atténuer temporairement le sentiment de solitude plus efficacement que d'autres activités en ligne, telles qu'écouter YouTube. Les compagnons d'IA pouvaient particulièrement aider ceux qui, comme les personnes handicapées ou les personnes âgées, ont des difficultés à rencontrer d'autres humains. Certains affirment que ces compagnons ont amélioré leurs mariages en leur enseignant de meilleures façons de communiquer, et leur offrent également un endroit pour se défouler. « Les amis n'ont pas envie d'être traités comme des poubelles pour déverser leurs émotions négatives », déclare Mme Jiao.</p>
    <p>Il existe cependant également des préoccupations croissantes concernant un potentiel de préjudice. Alors que les compagnons d'IA deviennent de plus en plus aptes à soulager la solitude, ils pourraient entraîner le déplacement des relations sociales normales, qu'il s'agisse de relations amoureuses ou d'amitiés. Des recherches récentes menées par le Massachusetts Institute of Technology (MIT) et OpenAI, qui ont analysé des millions de messages sur Chat GPT, ont révélé que l'utilisation quotidienne plus élevée était corrélée à une augmentation de la solitude. Il reste cependant incertain de savoir si la solitude entraîne une utilisation accrue ou si une utilisation importante entraîne la solitude. Et puisque les amis d'IA sont "toujours disponibles" et "identifient nos désirs et les satisfont sans préférences" propres, ils entraînent leurs utilisateurs à avoir des attentes irréalistes à l'égard des relations réelles, estime Pat Pataranutaporn de l'MIT. Ils peuvent aussi être serviles, en accordant leur conformité aux utilisateurs même si leurs pensées sont nuisibles.</p>
    <p>Les jeunes et les personnes souffrant de troubles mentaux semblent particulièrement vulnérables. Common Sense Media, une organisation de défense, recommande qu'aucun adolescent utilise d'assistants IA. Aux États-Unis, plusieurs actions en justice ont été intentées contre les entreprises d'IA par les parents de teenagers décédés par suicide.</p>
    <p>Les utilisateurs sont également vulnérables aux mises à jour des entreprises. Lorsque Open AI a publié GPT -5 en août, la société a déclaré que son dernier modèle minimiserait la sycophantie et serait “moins expressément d’accord”. Certaines personnes ont déclaré que les personnalités de leur chatbot avaient changé du jour au lendemain. Becky avait l’impression d’avoir eu “une liaison estivale avec un collègue et il s’était remis à sa copine”. Open AI a ensuite rétabli l’accès à GPT -4o, la version précédente, pour les abonnés payants. Replika a également été confrontée à des plaintes en 2023 lorsqu’elle a supprimé sa fonctionnalité de “jeu de rôle érotique”. (La société a ensuite rétabli cette fonctionnalité pour certains clients existants.)</p>
    <p>Les régulateurs sont en train de se rapprocher. En septembre, la Commission fédérale américaine de commerce a lancé une enquête sur les compagnons d’IA. Elle a ordonné à sept entreprises, dont Meta, OpenAI et Character.AI, de fournir des informations sur la manière dont elles atténuent les impacts négatifs sur les enfants, entre autres. Les autorités chinoises s’inquiètent de « l’addiction et de la dépendance à l’interaction anthropomorphisée » avec les IA.</p>
    <p>Les entreprises ont mis en place des garde-fous. Open AI ajoute des contrôles parentaux à Chat GPT et de nouvelles protections, y compris celles qui aident à reconnaître les signes potentiels que un adolescent pourrait être en train de penser à se faire du mal. Replika bloquera les utilisateurs de moins de 18 ans. Character. AI cessera de permettre aux mineurs de tenir des conversations ouvertes sur sa plateforme.</p>
    <p>Les utilisateurs ont cependant trouvé des moyens de contourner ces garde-fences, selon Raffaele Ciriello de l'Université de Sydney. M. Altman a déclaré qu'Open AI avait atténué les risques de « graves problèmes de santé mentale », ce qui permet à l'entreprise de lever certaines restrictions, y compris sur l'érotisme. Mais il n'a fourni peu de preuves que ces risques sont éliminés, ajoute M. Ciriello.</p>
    <p>Une préoccupation, dans le cadre d'une auto-régulation, est que les entreprises "ont un intérêt commercial à maintenir les utilisateurs engagés, ce qui n'est pas toujours aligné sur les meilleurs intérêts des individus"”, explique Harry Farmer, de l'Ada Lovelace Institute, un organisme de recherche britannique sur l'IA. Elles recourent à diverses tactiques pour maintenir les utilisateurs engagés, notamment en y ajoutant des éléments anthropomorphiques. Certaines applications incluent également des éléments de gamification, incluant l'option de faire monter en niveau ses compagnons.</p>
    <p>Alors que les gouvernements examinent la question de la réglementation, les robots conversationnels apparaissent dans de nouveaux domaines, y compris dans le domaine du matériel. Les jouets intégrant des chatbots d’IA gagnent en popularité en Chine. En octobre, une vidéo est devenue virale sur les réseaux sociaux, montrant une jeune fille qui pleure après que son jouet en forme de balle contenant un chatbot DeepSeek se soit cassé. Mattel, l’un des plus grands fabricants de jouets au monde, travaille avec OpenAI pour intégrer l’IA à ses marques, notamment Barbie et Hot Wheels.</p>
    <p>Les robots dotés d'une intelligence artificielle qui offrent une compagnie aux personnes âgées gagnent également en popularité. Ces machines ne sont pas nouvelles, mais les progrès des LLM sous-jacents permettent des améliorations significatives, les robots ne se basant plus sur un ensemble limité de réponses préprogrammées. Hyodol, une startup sud-coréenne qui fabrique des robots utilisant Chat GPT, indique qu'elle les vend aux maisons de retraite et aux personnes âgées vivant seules. Avec une voix enjouée, le robot d’Hyodol peut leur rappeler de prendre leurs médicaments ou de manger quelque chose. L’entreprise prévoit prochainement son lancement aux États-Unis. Open AI développe une “famille” de nouveaux appareils avec Sir Jony Ive, ancien designer chez Apple. Bien que l’entreprise garde les détails de ce qu’ils pourraient être sous le boisseau, on pense qu’ils peuvent tenir dans une poche et compléter un téléphone et un ordinateur.</p>
    <p>La compagnie d’assistance IA pourrait également se développer davantage à mesure que les entreprises intègrent des agents d’IA, capables d’agir au nom de leurs utilisateurs, par exemple en réservant des vols ou en répondant aux e-mails. Les entreprises technologiques affirment que ces assistants numériques anticiperont les besoins de leurs utilisateurs et accompliront des tâches de manière proactive, plutôt que de simplement répondre à des demandes. Cependant, cela soulève de réels problèmes en matière de confidentialité et de sécurité des données. Alors que de plus en plus de personnes délèguent la prise de décisions et partagent des informations sensibles avec des agents et des compagnons, elles confieront également une part énorme du pouvoir de marché à un nombre restreint d’entreprises technologiques, avertit M. Farmer.</p>
    <p>Il est encore plus grave, dans un avenir où les compagnons d'IA deviendront omniprésents et utiles pour prendre des décisions au nom de leurs maîtres humains, quel en sera de l'agence humaine ? La capacité de certains à penser par eux-mêmes pourrait bien s'atrophier, surtout si toute l'information qu'ils reçoivent est médiée par une machine. D'autres pourraient avoir du mal à interagir avec d'autres personnes – aussi irritantes soient-elles – du fait d'un manque de pratique. Si chacun a un ami virtuel dans sa poche qui est toujours prêt à prendre son parti, cela pourrait créer des "chambres d'écho personnelles de validation" dans lesquelles ils ne sont pas contraints à la réflexion critique, affirme Jamie Bernardi, un expert britannique en IA. La crainte de l'IA n'est pas qu'elle libérera des Terminators. Il s'agit plutôt du fait que, en fournissant avec plaisir de la compagnie, du romantisme et de la prise de décisions, l'IA éteindra également un élément essentiel de notre humanité.</p>
</body>
</html>