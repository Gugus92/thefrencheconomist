<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <title>Google a percé l'aura d'invulnérabilité de Nvidia</title>
    <style>
        body {
            font-family: 'Roboto', sans-serif;
            margin: 40px;
            line-height: 1.6;
            color: #333;
        }
        h1 {
            font-size: 2em;
            margin-bottom: 0.2em;
        }
        h2 {
            font-size: 1.4em;
            margin-top: 0;
            color: #666;
        }
        p {
            margin-top: 1em;
        }
    </style>
</head>
<body>
    <h1>Google a percé l'aura d'invulnérabilité de Nvidia</h1>
    <h2>Mais les puces personnalisées du géant de la recherche pourraient s'avérer délicates à adopter pour les autres.</h2>
    <p>Aucune entreprise n'a autant bénéficié de la frénésie autour de l'intelligence artificielle que Nvidia, qui est aujourd'hui l'entreprise la plus précieuse au monde. Au cours des trois dernières années, les investisseurs ont fait grimper ses actions en flèche, persuadés que sa domination du marché des puces d'IA est inattaquable. Les fabricants de puces concurrents et les startups ont tenté de s'imposer dans son domaine, sans grand succès.</p>
    <p>Maintenant, cependant, l'un des plus grands clients de Nvidia est devenu son concurrent le plus redoutable. Ce mois-ci, Google, qui a été le pionnier de l'architecture « transformer » qui sous-tend la vague actuelle d'IA, a lancé Gemini 3, un modèle de pointe qui surpasse ceux de ses plus grands rivaux, dont Open AI, sur la plupart des tests. Crucialement, Gemini 3 a été entraîné entièrement sur les propres puces de Google, appelées unités de traitement tensoriel (TPU), qu'elle a commencé à proposer à d'autres comme alternative moins coûteuse aux unités de traitement graphique (GPU) de Nvidia. Le mois dernier, Anthropic, un fabricant de modèles, a annoncé des projets d'utilisation jusqu'à 1 million de TPU de Google dans un accord rapporté à une valeur de plusieurs milliards de dollars. Des informations selon lesquelles Meta, un autre géant de la technologie avec de grandes ambitions en matière d'IA, serait également en pourparlers pour utiliser les puces de Google dans ses centres de données d'ici 2027 ont fait perdre à Nvidia plus de 100 milliards de dollars en valeur boursière, soit environ 3 % de son total, le 25 novembre, bien que la situation se soit en partie redressée depuis.</p>
    <p>Les clients de Nvidia ont un fort intérêt à explorer des alternatives moins coûteuses. Bernstein, un cabinet de recherche en investissement, estime que les GPU de Nvidia représentent plus des deux tiers du coût d'un rack de serveur IA typique. Les TPU de Google coûtent entre la moitié et un dixième du prix d'une puce Nvidia équivalente (voir graphique). Ces économies sont importantes, étant donné les sommes considérables actuellement investies dans la puissance de calcul pour l'IA. Bloomberg Intelligence, un autre groupe de recherche, prévoit que les dépenses d'investissement de Google atteindront 95 milliards de dollars l'année prochaine, près des trois quarts étant consacrés à l'entraînement et à l'exécution de modèles d'IA. Les investisseurs ont récemment pris conscience de l'énorme avantage financier que Google a acquis grâce à ses puces conçues en interne ; au cours des trois derniers mois, les actions de sa société mère, Alphabet, ont grimpé de moitié, ce qui en fait la troisième entreprise la plus précieuse au monde.</p>
    <p>D'autres géants de la technologie, dont Amazon, Meta et Microsoft, développent également des processeurs personnalisés, et le mois dernier, Open AI a annoncé une collaboration avec Broadcom, un concepteur de puces, pour développer son propre silicium. Mais aucun n'a progressé autant que Google. Ce dernier a commencé à concevoir ses puces il y a plus d'une décennie. À l'époque, les ingénieurs de Google avaient estimé que si les utilisateurs utilisaient une nouvelle fonctionnalité de recherche vocale sur leurs téléphones pendant seulement quelques minutes par jour, l'entreprise devrait doubler la capacité de ses centres de données, une prédiction qui a stimulé le développement d'un processeur plus efficace, conçu pour répondre aux besoins de Google. L'entreprise est désormais à sa septième génération de TPU. Jefferies, une banque d'investissement, estime que Google fabriquera environ 3 millions de ces puces l'année prochaine, soit presque la moitié du nombre d'unités produites par Nvidia.</p>
    <p>Pour les autres clients de Nvidia, cependant, passer aux puces de Google ne sera pas chose facile. La force de Nvidia réside en partie dans CUDA, la plateforme logicielle qui aide les programmeurs à tirer parti de ses GPU. Les développeurs d'IA s'y sont habitués. Et tandis que les logiciels entourant les TPU ont été créés dans l'optique de produits Google, notamment la recherche, CUDA est conçu pour répondre à un large éventail d'applications. De plus, estime Jay Goldberg de Seaport Research Partners, un analyste du secteur, il pourrait y avoir une limite à la volonté de Google de vendre ses TPU ; il pourrait préférer orienter les clients potentiels vers son service de cloud computing, très rentable. Pour contrer ses concurrents dans le domaine de l'IA, Google pourrait également être tenté de maintenir les prix de ses puces à un niveau élevé.</p>
    <p>Tout cela peut expliquer pourquoi Jensen Huang, le patron de Nvidia, ne semble pas particulièrement inquiet. Il a décrit Google comme « un cas très particulier », étant donné qu'il a commencé à développer des puces bien avant l'essor actuel de l'IA, et a qualifié les autres tentatives de « super adorables et simples ». Il mise également sur la flexibilité. L'architecture transformateur qui sous-tend les modèles d'IA actuels est encore en évolution. Les GPU, qui ont été initialement développés pour les jeux vidéo, sont très adaptables, permettant aux chercheurs en IA de tester de nouvelles approches. Nvidia pourrait ne plus paraître aussi invincible qu'elle l'était autrefois. Mais sa force ne devrait pas être sous-estimée. ■</p>
</body>
</html>